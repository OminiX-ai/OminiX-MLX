# Code Review: funasr-mlx vs FunASR Ecosystem

## Executive Summary

This document provides a comprehensive comparison between:
1. **funasr-mlx** (local Rust/MLX implementation)
2. **modelscope/FunASR** (original Python framework)
3. **FunAudioLLM/Fun-ASR** (newer LLM-based model)

---

## Project Overview

| Aspect | funasr-mlx | modelscope/FunASR | FunAudioLLM/Fun-ASR |
|--------|------------|-------------------|---------------------|
| Language | Rust + MLX | Python + PyTorch | Python + PyTorch |
| Focus | Paraformer inference | Full ASR toolkit | LLM-based ASR model |
| Models | Paraformer-large only | 51+ models | Fun-ASR-Nano (800M) |
| Purpose | Apple Silicon inference | Training + inference | Multilingual LLM ASR |
| Parameters | 220M | Various | 800M |

---

## 1. Architecture Comparison: Paraformer

### 1.1 Encoder Architecture

#### funasr-mlx (paraformer.rs:606-677)
```rust
SAN-M Encoder:
- 50 layers total
- First layer: 560 → 512 (LFR input)
- Remaining 49 layers: 512 → 512
- 4 attention heads, head_dim=128
- SANM kernel size: 11
- FFN: 512 → 2048 → 512
```

#### modelscope/FunASR (SANMEncoder)
```python
SANMEncoder:
- output_size: 512
- attention_heads: 4
- num_blocks: 50
- self_attention_type: "sanm"
- kernel_size: 11
- dropout_rate: 0.1
- positional_encoding_type: sinusoidal
```

**Verdict: ✅ MATCHES** - Encoder architecture is correctly implemented.

---

### 1.2 CIF Predictor

#### funasr-mlx (paraformer.rs:683-820)
```rust
CIF Predictor:
- Conv1d: 512 → 512, kernel=3, padding=1
- ReLU activation
- Linear: 512 → 1
- Sigmoid for alpha values
- Threshold: 1.0
- Tail threshold: 0.45
- Batch size: 1 only (limitation)
```

#### modelscope/FunASR (cif_predictor.py)
```python
CifPredictorV2:
- Padding layer for context
- Conv1d with groups=idim (depthwise)
- Sigmoid activation
- ReLU for smoothing
- threshold: 1.0
- order: 2 (left/right context)
- Supports arbitrary batch sizes
- Streaming support via forward_chunk()
```

**Findings:**

| Feature | funasr-mlx | FunASR | Status |
|---------|------------|--------|--------|
| Basic CIF algorithm | ✅ Yes | ✅ Yes | Match |
| Threshold (1.0) | ✅ Yes | ✅ Yes | Match |
| Tail threshold | ✅ 0.45 | ✅ configurable | Match |
| Batch support | ❌ batch=1 only | ✅ arbitrary | **GAP** |
| Streaming | ❌ No | ✅ Yes | **GAP** |
| Depthwise conv | ❌ Regular conv | ✅ groups=idim | **DIFFERENCE** |

**Issue: CIF Conv1d Implementation**

funasr-mlx uses regular Conv1d:
```rust
// paraformer.rs - regular convolution
Conv1d: 512 → 512, kernel=3
```

FunASR uses depthwise convolution:
```python
# cif_predictor.py - depthwise (more efficient)
Conv1d(idim, idim, kernel_size, groups=idim)
```

**Impact:** Functionally equivalent but depthwise is more efficient. Weight loading may need adjustment if source weights are depthwise.

---

### 1.3 Decoder Architecture

#### funasr-mlx (paraformer.rs:997-1104)
```rust
Paraformer Decoder:
- Token embedding: 8404 → 512
- 16 decoder layers
- Final FFN block
- Output projection: 512 → 8404

Decoder Layer:
- Self-attention FSMN (depthwise conv)
- Cross-attention to encoder
- FFN: 512 → 2048 → 512
- 3 LayerNorms per layer
```

#### modelscope/FunASR (decoder.py)
```python
ParaformerSANMDecoder:
- num_blocks: 16
- attention_heads: 8
- feed_forward_size: 2048
- dropout_rate: 0.1
```

**Findings:**

| Feature | funasr-mlx | FunASR | Status |
|---------|------------|--------|--------|
| Layers | 16 | 16 | ✅ Match |
| Attention heads | 4 | 4 | ✅ Match |
| FFN size | 2048 | 2048 | ✅ Match |
| Self-attn type | FSMN | SANM | ✅ Match |

**Note on Decoder Attention Heads**

The funasr-mlx code defaults to 4 heads (paraformer.rs:135), matching Paraformer-large architecture. The FunASR template.yaml shows 8 heads as a generic default, but actual Paraformer-large uses 4 heads. This is correct.

---

## 2. Audio Processing Pipeline

### 2.1 Feature Extraction

#### funasr-mlx (paraformer.rs:148-370)
```rust
MelFrontend:
1. Scale: audio * 32768.0 (Kaldi convention)
2. Pre-emphasis: coef = 0.97
3. STFT: manual DFT (no FFT library)
   - n_fft: 400 (25ms @ 16kHz)
   - hop_length: 160 (10ms)
   - Hamming window
4. Mel filterbank: 80 bins
5. Log amplitude: log(max(spec, 1e-10))
6. LFR stacking: 7 frames, stride 6
   - Output: 560 features (80 * 7)
7. CMVN: (x + addshift) * rescale
```

#### modelscope/FunASR (frontends/default.py)
```python
DefaultFrontend:
1. STFT: 512-point FFT, 128-sample hop (different!)
2. Optional speech enhancement (WPE/MVDR)
3. Power spectrum: real² + imag²
4. Log-Mel-Filterbank: 80 bins
5. Optional CMVN normalization
```

**Critical Differences:**

| Parameter | funasr-mlx | FunASR Default | Paraformer Actual |
|-----------|------------|----------------|-------------------|
| n_fft | 400 | 512 | 400 (25ms) |
| hop_length | 160 | 128 | 160 (10ms) |
| Pre-emphasis | 0.97 | Optional | 0.97 |
| LFR | 7/6 | Via SpecAugLFR | 7/6 |
| Audio scaling | 32768.0 | 1.0 | 32768.0 (Kaldi) |

**Verdict:** funasr-mlx follows Paraformer-specific settings correctly. The FunASR default frontend is generic; Paraformer uses custom settings.

---

### 2.2 STFT Implementation

#### funasr-mlx Issue: Manual DFT
```rust
// paraformer.rs:199-235 - Manual DFT implementation
// No FFT library, O(N²) complexity
for k in 0..n_freqs {
    for n in 0..window_size {
        // Manual sin/cos computation
    }
}
```

**Performance Impact:**
- O(N²) vs O(N log N) for FFT
- For n_fft=400: ~160,000 operations vs ~3,500
- ~45x slower for STFT computation

**Recommendation:** Use `rustfft` crate or MLX FFT operations for significant speedup.

---

### 2.3 Audio Loading

#### funasr-mlx (audio.rs:19-126)
```rust
Supported formats:
- 16-bit PCM WAV
- 24-bit PCM WAV
- 32-bit float WAV
- Automatic stereo → mono conversion
- Normalization to [-1, 1]
```

#### FunASR
```python
# Relies on torchaudio/soundfile
# Supports: WAV, FLAC, MP3, OGG, etc.
```

**Gap:** funasr-mlx only supports WAV format.

---

### 2.4 Resampling

#### funasr-mlx (audio.rs:128-213)
```rust
Primary: Windowed sinc interpolation (rubato crate)
- Sinc length: 256
- Cutoff: 0.95
- Interpolation: Cubic
- Oversampling: 256
- Window: Blackman-Harris

Fallback: Linear interpolation
```

**Verdict: ✅ HIGH QUALITY** - Uses professional-grade resampling algorithm.

---

## 3. Decoding Strategies

### 3.1 Current Implementation

#### funasr-mlx
```rust
// CIF-based non-autoregressive decoding only
// No beam search
// No CTC decoding
// No language model rescoring
```

#### modelscope/FunASR (search.py)
```python
BeamSearchPara:
- Configurable beam width
- Multiple scorer support (decoder, LM, etc.)
- Weighted score combination
- Length normalization
- Timestamp prediction
```

**Gaps:**

| Feature | funasr-mlx | FunASR | Priority |
|---------|------------|--------|----------|
| Beam search | ❌ No | ✅ Yes | Medium |
| CTC decoding | ❌ No | ✅ Yes | Low |
| LM rescoring | ❌ No | ✅ Yes | Low |
| Timestamps | ❌ No | ✅ Yes | Medium |

**Note:** For Paraformer, CIF-based decoding is the primary method. Beam search provides marginal improvements but adds latency.

---

## 4. Model Configuration Comparison

### 4.1 Paraformer-large (220M)

| Parameter | funasr-mlx | FunASR | Match |
|-----------|------------|--------|-------|
| sample_rate | 16000 | 16000 | ✅ |
| n_mels | 80 | 80 | ✅ |
| n_fft | 400 | 400 | ✅ |
| hop_length | 160 | 160 | ✅ |
| lfr_m | 7 | 7 | ✅ |
| lfr_n | 6 | 6 | ✅ |
| encoder_dim | 512 | 512 | ✅ |
| encoder_layers | 50 | 50 | ✅ |
| encoder_heads | 4 | 4 | ✅ |
| encoder_ffn | 2048 | 2048 | ✅ |
| sanm_kernel | 11 | 11 | ✅ |
| cif_threshold | 1.0 | 1.0 | ✅ |
| decoder_dim | 512 | 512 | ✅ |
| decoder_layers | 16 | 16 | ✅ |
| decoder_heads | 4 | 4 | ✅ |
| vocab_size | 8404 | 8404 | ✅ |

---

## 5. Weight Loading

### 5.1 funasr-mlx Implementation (paraformer.rs:1200-1379)

```rust
Weight Mapping:
- Encoder first layer: encoder.encoders0.0.*
- Regular encoder layers: encoder.layers.{i}.*
- CIF predictor: predictor.*
- Decoder embedding: decoder.embed.0.weight
- Decoder layers: decoder.layers.{i}.*
- Final FFN: decoder.decoders3.0.*
- Output projection: decoder.output_proj.*

Conv1d transpose: [out, in, kernel] → [kernel, in, out]
```

### 5.2 CMVN Loading (paraformer.rs:1382-1459)

```rust
// Parses FunASR native XML-like format
// Expected: 560 values (80 mels * 7 LFR frames)
<AddShift> [ val1 val2 ... val560 ] </Rescale>
<Rescale> [ val1 val2 ... val560 ] </Nnet>
```

**Verdict: ✅ CORRECT** - Weight mapping follows FunASR conventions.

---

## 6. Missing Features vs FunASR

### 6.1 Model Support

| Model | FunASR | funasr-mlx | Priority |
|-------|--------|------------|----------|
| Paraformer-zh | ✅ | ✅ | - |
| Paraformer-en | ✅ | ❌ | High |
| Paraformer-streaming | ✅ | ❌ | High |
| Conformer | ✅ | ❌ | Medium |
| SenseVoice | ✅ | ❌ | Medium |
| Whisper | ✅ | ❌ | Low |

### 6.2 Supporting Features

| Feature | FunASR | funasr-mlx | Priority |
|---------|--------|------------|----------|
| VAD (fsmn-vad) | ✅ | ❌ | High |
| Punctuation (ct-punc) | ✅ | ❌ | Medium |
| Timestamps | ✅ | ❌ | Medium |
| Speaker diarization | ✅ | ❌ | Low |
| Keyword spotting | ✅ | ❌ | Low |
| Emotion recognition | ✅ | ❌ | Low |

### 6.3 Processing Features

| Feature | FunASR | funasr-mlx | Impact |
|---------|--------|------------|--------|
| Streaming inference | ✅ | ❌ | High - real-time use |
| Batch processing | ✅ | ❌ (batch=1) | Medium - throughput |
| Multi-format audio | ✅ | ❌ (WAV only) | Low |
| GPU batching | ✅ | Partial | Medium |

---

## 7. Comparison with FunAudioLLM/Fun-ASR

Fun-ASR is a **different architecture** (LLM-based, 800M params) that provides:

| Feature | Fun-ASR | funasr-mlx | Notes |
|---------|---------|------------|-------|
| Architecture | LLM-based | Paraformer | Different approach |
| Parameters | 800M | 220M | 3.6x larger |
| Languages | 31 | Chinese only | Fun-ASR more versatile |
| Dialects | 7 Chinese + 26 accents | Standard Mandarin | Fun-ASR more robust |
| Streaming | ✅ Yes | ❌ No | - |
| Far-field | ~93% accuracy | Unknown | Fun-ASR optimized |

**Recommendation:** Fun-ASR represents the next generation. Consider porting it for multilingual/robust ASR needs.

---

## 8. Performance Analysis

### 8.1 funasr-mlx Benchmarks (Apple M3 Max)

| Audio Duration | Inference Time | RTF | Speed |
|----------------|----------------|-----|-------|
| 3s | 50ms | 0.017 | 59x RT |
| 10s | 150ms | 0.015 | 67x RT |
| 30s | 400ms | 0.013 | 75x RT |

### 8.2 Bottlenecks

1. **Manual STFT** - ~45x slower than FFT-based
2. **CIF batch=1** - Cannot leverage GPU parallelism
3. **No streaming** - Must process entire audio at once

### 8.3 Optimization Opportunities

| Optimization | Estimated Speedup | Effort |
|--------------|-------------------|--------|
| Use FFT library | 2-5x for audio preprocessing | Low |
| Batch support | 2-4x for throughput | Medium |
| Streaming | N/A (enables real-time) | High |
| Metal kernel fusion | 1.2-1.5x | Medium |

---

## 9. Code Quality Assessment

### 9.1 Strengths

1. **Clean architecture** - Well-separated concerns (audio, model, error handling)
2. **Comprehensive error handling** - Custom Error enum with thiserror
3. **High-quality resampling** - Professional-grade rubato integration
4. **MLX integration** - Proper GPU acceleration via Metal
5. **Documentation** - Module-level docs and inline comments

### 9.2 Weaknesses

1. **Limited model support** - Only Paraformer-large
2. **No streaming** - Cannot do real-time transcription
3. **Batch=1 limitation** - CIF predictor bottleneck
4. **Manual STFT** - Performance penalty
5. **WAV only** - Limited audio format support

### 9.3 Code Locations

| Component | File | Lines |
|-----------|------|-------|
| Main model | paraformer.rs | 1-1512 |
| Audio processing | audio.rs | 1-263 |
| Error handling | error.rs | 1-32 |
| Public API | lib.rs | 1-100 |
| Vocabulary | lib.rs | 45-99 |

---

## 10. Recommendations

### Priority 1: Critical Fixes

1. **Add FFT library** - Replace manual DFT with `rustfft` for 2-5x speedup in audio preprocessing

### Priority 2: High-Impact Features

1. **Streaming support** - Enable real-time transcription
2. **Batch processing** - Support batch_size > 1 in CIF
3. **VAD integration** - Add voice activity detection for long audio

### Priority 3: Model Expansion

1. **Paraformer-en** - English speech recognition
2. **SenseVoice** - Multilingual with emotion/events
3. **Fun-ASR-Nano** - LLM-based for robustness

### Priority 4: Quality of Life

1. **More audio formats** - MP3, FLAC, OGG support
2. **Timestamp output** - Word-level timing
3. **Punctuation restoration** - ct-punc integration

---

## 11. Summary Table

| Category | Status | Notes |
|----------|--------|-------|
| **Core Architecture** | ✅ Correct | Matches FunASR Paraformer |
| **Audio Pipeline** | ✅ Correct | Proper Kaldi-style preprocessing |
| **Feature Extraction** | ⚠️ Slow | Manual DFT needs FFT replacement |
| **CIF Predictor** | ⚠️ Limited | batch=1 only, no streaming |
| **Decoder** | ✅ Correct | 16 layers, 4 heads matches |
| **Weight Loading** | ✅ Correct | Proper mapping and transpose |
| **Decoding** | ✅ Basic | CIF-based, no beam search |
| **Performance** | ✅ Good | 59-75x real-time |
| **Feature Coverage** | ❌ Limited | Missing VAD, streaming, batch |

---

## Conclusion

**funasr-mlx** is a **functionally correct** implementation of FunASR's Paraformer model for Apple Silicon, achieving excellent inference performance (59-75x real-time). The core architecture matches the Python reference.

**Key gaps** are:
1. No streaming support (limits real-time use)
2. Batch=1 limitation (limits throughput)
3. Manual STFT (performance penalty)
4. Single model only (no English/multilingual)

**Recommended next steps:**
1. Replace manual DFT with FFT library (easy win)
2. Add streaming inference support (high value)
3. Port Paraformer-en for English support
4. Consider Fun-ASR-Nano for robust multilingual ASR
